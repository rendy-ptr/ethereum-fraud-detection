{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_gradient_boosting_tuning(X_train, y_train, X_test, y_test):\n",
    "    # Define the parameter grid for tuning\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.1, 0.5],\n",
    "        'max_iter': [100, 200, 500],\n",
    "        'max_depth': [3, 5, 7, None],\n",
    "        'min_samples_leaf': [1, 5, 10],\n",
    "        'l2_regularization': [0, 0.1, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Create the HistGradientBoostingClassifier\n",
    "    hist_gb = HistGradientBoostingClassifier(random_state=42)\n",
    "    \n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=hist_gb, \n",
    "        param_grid=param_grid, \n",
    "        cv=5,  # 5-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"\\nBest Cross-Validation Score:\", grid_search.best_score_)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Detailed Classification Report\n",
    "    # print(\"\\nClassification Report:\")\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix Visualization\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    # plt.title('Confusion Matrix - HistGradientBoostingClassifier')\n",
    "    # plt.ylabel('True Label')\n",
    "    # plt.xlabel('Predicted Label')\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig('confusion_matrix.png')\n",
    "    # plt.close()\n",
    "    \n",
    "    # Save the best model\n",
    "    # joblib.dump(best_model, 'best_hist_gradient_boosting_model.joblib')\n",
    "    \n",
    "    return best_model, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load the data\n",
    "    data = np.load('../../Data/#1/processed_data.npz')\n",
    "    x_tr_resample = data['x_tr_resample']\n",
    "    y_tr_resample = data['y_tr_resample']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    X_train = data['X_train']\n",
    "\n",
    "    with open('../../Data/#1/power_transformer.pkl', 'rb') as f:\n",
    "        norm = pickle.load(f)\n",
    "\n",
    "    # Load normalization transformer\n",
    "    # norm = joblib.load('../../Data/#1/power_transformer.joblib')\n",
    "\n",
    "    # Normalize features\n",
    "    norm_train_feature = norm.fit_transform(X_train)\n",
    "    norm_test_feature = norm.transform(X_test)\n",
    "\n",
    "    best_model, best_params = hist_gradient_boosting_tuning(\n",
    "        x_tr_resample, \n",
    "        y_tr_resample, \n",
    "        norm_test_feature, \n",
    "        y_test\n",
    "    )\n",
    "\n",
    "    print(\"\\nHyperparameter Tuning Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "Best Hyperparameters: {'l2_regularization': 0, 'learning_rate': 0.1, 'max_depth': None, 'max_iter': 500, 'min_samples_leaf': 10}\n",
      "\n",
      "Best Cross-Validation Score: 0.9900245298446444\n",
      "Accuracy: 98.07%\n",
      "\n",
      "Hyperparameter Tuning Complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
